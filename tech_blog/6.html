<p>I have been coding since I was a freshman in college (2016) but it
took me this long (9 years) to make my first open source
contribution.</p>
<p>The repo is <a
href="https://github.com/apache/arrow-rs">apache/arrow-rs</a> (pure rust
implementation of Apache Arrow). I had some time on my hands and wanted
to enhance my Rust skills by working on a large and widely used open
source project. I have tried to make pull requests to open source
projects before, but I was either met with resistance, ghosting,
immediate closure with a vague reason, or what almost seems like an
intentional misunderstanding of my contribution.</p>
<p>I wanted to be mature this time. I had time to make a high quality
contribution, learn the code base sufficiently enough, explain my
solution so that it is hard to misunderstand it, and make the
contribution so mouth wattering that the maintainers would be begging to
merge it.</p>
<p>Easier said than done. Here is my story of issue <a
href="https://github.com/apache/arrow-rs/issues/7273">#7273</a></p>
<h2 id="repository-selection">Repository Selection</h2>
<p>So which repo should I choose? Well there are a lot of repos out
there that have maintainers who have a big ego, either they are part of
a company and their only priority is to make money by adding features
and not look at technical debt clean up contributions, or just
contributors who get mad when you point out an issue with their
“perfect” code.</p>
<p>What I did was ask for a recommendation. Luckilly I was able to talk
to <a href="https://www.linkedin.com/in/dennyglee/">Denny Lee</a> the
Director of Development Relations at Databricks, at a <a
href="https://www.meetup.com/bellevue-gdg">PyData Seattle meet up</a>.
He was speeking about all the open source libraries Databricks makes use
of, some of which are implemented in Rust. I went up to him after the
presentation and asked what open source projects have a good culture
behind them that I may be able to contribute some code to? He said so
many that I could not keep up, but one of them I remembered was Apache
Arrow.</p>
<p>So I looked up Apache Arrow, and saw that it was not a Rust
repository, it was written in C. It was also hosted and managed by
isoteric tooling (not GitHub). I got sad, until I asked an LLM if it
knew a Rust version of the repo, and it pointed me directly there (Why
is SEO so bad now adays?). Once I found it, I was elated. I felt like I
was living on a prayer enough so that I was determined to make this repo
be the one to contribute to.</p>
<h2 id="issue-selection">Issue Selection</h2>
<p>I first took a look at the activity of the repo. I saw contributions
from hundreds of contributors within the past year (a good sign). I saw
that more than one person was approving pull requests. I saw that on
many issues, there was multiple people weighing in on the correct
implementation, and it seemed like a cordial discussion (a good
sign).</p>
<p>Now how do I even contribute? I dont want to have to sign up for some
account on another website just to sign a contributor agreement or
something. Also like how do you know that you are the only one working
on an issue at a time so your effort is not wasted? Are there different
levels of contributors that can touch different segments of the code and
if I am not at that level yet, would my contribution be laughed at?</p>
<p>Luckilly in the README it gives instructions to new contributors of
the codebase. After reading it, I was supprised that I understood just
about everything that was explained there. No dogmatic Makefiles, no
hacked testing/benching system, just the standard Rust tooling which I
was already comfortable with.</p>
<p>The README also talked about how there was an issue tag called
<code>good first issue</code> where maintainers would tag such that
newer contributors could pick up easily. I looked at those tags, and was
surprised to find that there were only 20, and most of them had either a
bunch of discussion that came to the conclusion that the solution was
too hard or infeasable, or I had no idea what the issue was talking
about</p>
<p>If only there was an issue that someone explained really well, was a
one or two line change, that had almost no testing/benching complexity,
that you only needed to understand one file to understand the scope of
the fix, and that had a link to code that already implemented and tested
a fix for (so I did not need to do it myself). Well, you are in luck
because I found an issue exactly matching that description.</p>
<p>Welcome to issue <a
href="https://github.com/apache/arrow-rs/issues/7273">#7273</a>. The
issue wanted the integer/float to string conversion to be faster, by
using no extra copies. I actually understand what that means! This issue
was actually created by one of the maintainers which is a good sign,
maybe he will actually look at my contribution. There was a proposed
solution by the maintainer, and a contributor already implemented a
solution and a benchmark, but unfortunately the new solution benched
slower than what was there, so they gave up, but they linked to their
branch they committed code to.</p>
<h2 id="implementation">Implementation</h2>
<p>I was excited, I had some working code and a benchmark to work with,
so I checked out the code and ran the bench and saw it was running
slower, and was perplexed since it did elimitate one copy. The benchmark
seemed like a good test case, but then the issue stood out to me. Was
the benchmark even testing the correct code path? A simple print
debugging test revealed that it was not. Then I changed the benchmark to
test the correct code path, and I saw a 50 percent improvement in
runtime!</p>
<p>I figured I could just fix the benchmark and call it done, but there
was some extra credit put in the description of the issue. We could
possibly use an external library to make the runtime even faster. I
added this and saw that the runtime was truly even faster! a full half
reduction in runtime speed across the corrected benchmarks. I was even
more elated, so I submitted my code and tagged the creator of the issue
to ask for a review</p>
<h2 id="maintainer-argument">Maintainer Argument</h2>
<p>To my surprise, the maintainer acknowledged my submission the next
day and ran some automated benchmark on the code, and all the code
related to conversions regressed by 15 percent. What happened? Also I
saw his automated benchmark did not include my new benchmark. He said he
would not merge it because it regressed. I had to run the benchmarks
myself to see them for my eyes that they regresses, and he was correct,
other types of conversions were slower. That made no sense to me since I
did not change that code path. The only thing I could think of that
changed was some compiler optimization was able to run when the code
around other conversions were simpler and it was not able to run if the
file contained more complex logic? I guess it was possible, but I did
not know compile internals enough to prove it.</p>
<p>I asked the maintainer why that if there was a 15 percent regression
in other data types and a 100% speed up of integer and float conversions
that that would not be grounds for inclusion anyway? He ignored me. I
was mad. I was feeling this was turning into one of those things where
even though it was the best for the project, the maintainer could still
block it because he has the power and he uses it however he feels like
it (he has a soft spot for strings over integers?)</p>
<h2 id="another-idea">Another idea</h2>
<p>3 months passed (3 months!). Still mad, I was reading that the Rust
compiler only does vectorization optimizations for x86_64 CPUs that were
built in the year 2000. There were a lot of vector instruction
improvements to the ISA since then, which are included in newer CPUs,
which I assumed most Apache Arrow RS code was running on. The only issue
is that you have to run the Rust compiler with a flag that tells it to
optimize for the newest vectorization instructions.</p>
<p>I just wanted to test for myself to see if benchmarking the code I
wrote to speed up int to string conversions would test faster with newer
vectorization hardware. So I did, I created a benchmark with and without
the vectorization flag, and found something unexpected. the int/float to
string conversions were not faster, but there was something that did not
change that suprised me. The other types conversion to string code
seemed to not regress anymore with the new vector instructions even with
the optimizations I wrote for the int?float types.</p>
<p>This gives me some sort of proof that I may not be the cause of the
regression and it was the compiler choosing things. I knew it was a long
shot but I tagged the maintainer again and asked him to run another
benchmark against my change with the different compiler flag, and the
results shocked me for an even different reason. The maintainer was
actually excited to do that and did it a day later. The benchmarks
actually turned out to not regress with the compiler flag turned on as
well as turned off!</p>
<p>That makes no sense? How can something regress significantly one time
but not regress 3 months later with the same code? The only answer I
could think of was that since the code base was configured to use a
newer Rust version to compile the code, maybe the same compiler
optimization used to optimize the code before I touched it was finally
changed to run on my implemented int/float optimization logic too.</p>
<p>Anyway the maintainer immediately saw that there were no regressions
like before and that there was a 100% speed up of int/float conversions,
and he had no choice but to drool and merge the code! The code was
merged on Sep 29 2025!</p>
